
model_args:
  evaluate_during_training: true
  fp16: false
  gradient_accumulation_steps: 1
  use_multiprocessing: false
  learning_rate: 2.0e-04
  manual_seed: 42
  max_seq_length: 512
  num_train_epochs: 100
  pretrained_path: ./outputs/best_mlm_uspto_pretrain
  output_dir: ./out/Parrot_train_in_USPTO_Condition
  best_model_dir: ./outputs/Parrot_train_in_USPTO_Condition
  overwrite_output_dir: true
  regression: false
  thread_count: 8
  train_batch_size: 8
  wandb_project: Parrot_train_in_USPTO_Condition
  warmup_ratio: 0.0
  decoder_args:
    d_model: 256
    dim_feedforward: 256
    dropout: 0.1
    nhead: 4
    num_decoder_layers: 3
    tgt_vocab_size: None

dataset_args:
  use_temperature: false
  dataset_root: dataset/source_dataset/USPTO_condition_final
  database_fname: USPTO_condition.csv
testset_args:
  testset_distinguish_catalyst: false
  topk_results_fname: topk_accuracy.csv
  beam:   # effective when testset_distinguish_catalyst=false
    0: 1  # c1
    1: 3  # s1
    2: 1  # s2
    3: 5  # r1
    4: 1  # r2
  test_condition_items:
    - c1
    - s1
    - s2
    - r1
    - r2